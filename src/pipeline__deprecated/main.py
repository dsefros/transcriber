#!/usr/bin/env python3
"""
–ï–¥–∏–Ω—ã–π pipeline –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å—Ç—Ä–µ—á:
1. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è + –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ WhisperX (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –∞—É–¥–∏–æ—Ñ–∞–π–ª)
2. –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é LLM (Ollama/llama-cpp)
3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –≤ Markdown
4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ Postgres –∏ Qdrant (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ)

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç offline-—Ä–µ–∂–∏–º –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞.
"""
import os
import sys
import json
import gc
from pathlib import Path
from dotenv import load_dotenv
import torch
import ollama
from datetime import datetime
import hashlib
import traceback

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
load_dotenv()
INPUT_DIR = os.getenv("INPUT_DIR", "input")
OUTPUT_DIR = os.getenv("OUTPUT_DIR", "output")
HF_TOKEN = os.getenv("HF_TOKEN")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# === –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö ===
from src.storage.postgres import init_db, get_db_session, Meeting, Speaker, Fragment
from src.storage.qdrant import init_qdrant_client, create_collections_if_not_exists

# === –ò–º–ø–æ—Ä—Ç –Ω–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ===
from src.config.models import get_models_config
from src.ai.generator import generate_text

def _free_gpu_memory():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –≤—Å–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ —ç—Ç–∞–ø–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    gc.collect()
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ PyTorch
    if hasattr(torch.cuda, 'cudnn'):
        torch.backends.cudnn.benchmark = False
    if torch.cuda.is_available():
        print(f"[DEBUG] VRAM –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {torch.cuda.memory_allocated() / 1024**2:.1f} / {torch.cuda.get_device_properties(0).total_memory / 1024**2:.1f} MB")

# === –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –∑–∞–≥—Ä—É–∑–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ JSON ===
def load_segments_from_json(json_path: str) -> tuple[list, str, str, float]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ JSON.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (—Å–µ–≥–º–µ–Ω—Ç—ã, –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –∞—É–¥–∏–æ—Ö–µ—à, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if 'transcription' not in data:
        raise ValueError(f"JSON –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª—è 'transcription': {json_path}")
    
    segments = [
        {
            'speaker': seg['speaker'],
            'text': seg['text'],
            'start': seg['start'],
            'end': seg['end']
        }
        for seg in data['transcription']
    ]
    
    metadata = data.get('metadata', {})
    orig_filename = metadata.get('filename', Path(json_path).stem)
    audio_hash = metadata.get('audio_hash', hashlib.sha256(Path(json_path).name.encode()).hexdigest()[:16])
    duration = metadata.get('duration_sec', sum(seg['end'] - seg['start'] for seg in segments))
    
    return segments, orig_filename, audio_hash, duration

# === 1. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ transcribe_v3.py) ===
def transcribe_and_diarize(audio_path: str, device: str = "cuda"):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è + –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ WhisperX —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ–º –ø–∞–º—è—Ç–∏."""
    import whisperx
    from pydub import AudioSegment
    
    print(f"[DEBUG] –ó–∞–≥—Ä—É–∑–∫–∞ WhisperX (large-v3) –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}")
    model = whisperx.load_model("large-v3", device, compute_type="float16" if device == "cuda" else "int8")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV 16kHz –º–æ–Ω–æ
    print("[DEBUG] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ WAV...")
    audio = AudioSegment.from_file(audio_path)
    audio = audio.set_channels(1).set_frame_rate(16000)
    wav_path = "temp_audio.wav"
    audio.export(wav_path, format="wav")
    
    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
    print("[DEBUG] –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è...")
    audio_data = whisperx.load_audio(wav_path)
    result = model.transcribe(audio_data, language="ru")
    
    # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    model_a, metadata = whisperx.load_align_model(
        language_code="ru",
        device=device,
        model_name="facebook/wav2vec2-base-960h"
    )
    result = whisperx.align(result["segments"], model_a, metadata, audio_data, device)
    
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –°–†–ê–ó–£ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    del model_a
    _free_gpu_memory()
    
    # –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è
    print("[DEBUG] –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è...")
    diarize_model = whisperx.DiarizationPipeline(use_auth_token=HF_TOKEN, device=device)
    diarize_segments = diarize_model(audio_data)
    result = whisperx.assign_word_speakers(diarize_segments, result)
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    segments = []
    for seg in result["segments"]:
        segments.append({
            "text": seg.get("text", "").strip(),
            "start": round(seg.get("start", 0), 2),
            "end": round(seg.get("end", 0), 2),
            "speaker": seg.get("speaker", "SPEAKER_00")
        })
    
    # üî• –ö–†–ò–¢–ò–ß–ù–û: –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º –í–°–ï –º–æ–¥–µ–ª–∏ –∏ –¥–∞–Ω–Ω—ã–µ —ç—Ç–∞–ø–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    del model
    del diarize_model
    del audio_data
    del result
    del diarize_segments
    _free_gpu_memory()
    
    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    if os.path.exists(wav_path):
        os.remove(wav_path)
    
    print(f"[DEBUG] WhisperX –∑–∞–≤–µ—Ä—à—ë–Ω. –°–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")
    return segments

# === 2. –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Ollama (–ª–æ–∫–∞–ª—å–Ω–∞—è LLM) ===
def analyze_with_model(segments: list) -> str:
    """–ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ —á–µ—Ä–µ–∑ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (Ollama –∏–ª–∏ llama-cpp)."""
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –º–æ–¥–µ–ª–∏
    models_cfg = get_models_config()
    profile = models_cfg.get_active_profile()
    print(f"[DEBUG] –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ {profile.backend} ({profile.key})...")
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    dialogue = "\n".join([f"{seg['speaker']}: {seg['text']}" for seg in segments if seg["text"]])
    
    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    system_prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –≤—Å—Ç—Ä–µ—á –≤ –∫–æ–º–ø–∞–Ω–∏–∏ –°–æ–º–º–µ—Ä—Å. –°–æ–º–º–µ—Ä—Å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ IT-—Ä–µ—à–µ–Ω–∏—è—Ö –¥–ª—è —ç–∫–≤–∞–π—Ä–∏–Ω–≥–∞, POS-—Ç–µ—Ä–º–∏–Ω–∞–ª–æ–≤ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å–∞. –¢–≤–æ–∏ –∫–ª–∏–µ–Ω—Ç—ã ‚Äî –±–∞–Ω–∫–∏, —Ä–∏—Ç–µ–π–ª –∏ —á–∞—Å—Ç–Ω—ã–µ –º–µ—Ä—á–∞–Ω—Ç—ã.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ô –û–¢–ß–Å–¢ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ —Ä–∞–∑–¥–µ–ª–∞–º–∏:
### üìù –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
- –û–±—â–∞—è —Ç–µ–º–∞ –≤—Å—Ç—Ä–µ—á–∏ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
### ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è
–î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è:
- –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (–∫—Ä–∞—Ç–∫–æ)
- –ö—Ç–æ –æ–∑–≤—É—á–∏–ª –ø—Ä–æ–±–ª–µ–º—É (—Å–ø–∏–∫–µ—Ä)
- –°—É—Ç—å –ø—Ä–æ–±–ª–µ–º—ã
- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
- –ö—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–∏–ª —Ä–µ—à–µ–Ω–∏–µ (—Å–ø–∏–∫–µ—Ä)
- –°—Ç–∞—Ç—É—Å —Ä–µ—à–µ–Ω–∏—è (—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ/–≤ —Ä–∞–±–æ—Ç–µ/—Ç—Ä–µ–±—É–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è)
–í–ê–ñ–ù–û:
1. –ï—Å–ª–∏ –≤ –¥–∏–∞–ª–æ–≥–µ –µ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö.
2. –ï—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å —É–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Å—Ä–æ–∫ ("—Å–µ–≥–æ–¥–Ω—è", "–Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ") ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã {datetime.now().strftime('%d.%m.%Y')}.
3. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª—è—Ö: –°–ë–ü, —Ç–µ—Ä–º–∏–Ω–∞–ª—ã (Ingenico/Newland), –ø—Ä–æ—à–∏–≤–∫–∏, –≤–æ–∑–≤—Ä–∞—Ç—ã, —Å—Ç–µ–π—Ç-—Ö–æ–ª–¥–µ—Ä—ã, –ª–æ–≥–∏.
4. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –≤ –¥–∏–∞–ª–æ–≥–µ.
5. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–ø–æ–ª–Ω–∞—è ‚Äî –ø–æ–º–µ—á–∞–π —Å—Ç–∞—Ç—É—Å –∫–∞–∫ "–¢—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è".
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
"""
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    try:
        if profile.backend == "ollama":
            # –î–ª—è Ollama –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Ç-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π —Ä–æ–ª—å—é
            response = ollama.chat(
                model=profile.name,
                messages=[
                    {"role": "system", "content": system_prompt.strip()},
                    {"role": "user", "content": f"–î–∏–∞–ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{dialogue}"}
                ],
                options={
                    "temperature": profile.params.get("temperature", 0.1),
                    "top_p": profile.params.get("top_p", 0.9),
                    "repeat_penalty": profile.params.get("repeat_penalty", 1.15),
                    "num_predict": profile.params.get("num_predict", 2000),
                },
                stream=False
            )
            return response["message"]["content"].strip()
        else:
            # –î–ª—è llama-cpp –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å generate_text()
            full_prompt = f"–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –≤—Å—Ç—Ä–µ—á –≤ –∫–æ–º–ø–∞–Ω–∏–∏ –°–æ–º–º–µ—Ä—Å.\n{system_prompt.strip()}\n–î–∏–∞–ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{dialogue}"
            return generate_text(full_prompt, profile)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        return f"‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**\n–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏:\n`{str(e)}`\n\n**–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∞:**\n{dialogue[:1000]}..."

# === 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ ===
def extract_technical_terms(text: str) -> list:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    technical_terms = [
        'TSP', '–ü–ò–æ–¢', '–ï–ì–ê–ò–°', '–º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞', '–æ—Ñ–ª–∞–π–Ω', '–ß–µ—Å—Ç–Ω—ã–π –ó–ù–ê–ö',
        '–°–ë–ü', '—ç–∫–≤–∞–π—Ä–∏–Ω–≥', 'POS', '—Ç–µ—Ä–º–∏–Ω–∞–ª', '–ø—Ä–æ—à–∏–≤–∫–∞', '–≤–æ–∑–≤—Ä–∞—Ç—ã',
        '—Å—Ç–µ–π—Ç-—Ö–æ–ª–¥–µ—Ä—ã', '–ª–æ–≥–∏', 'API', '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å',
        'Sommers', '–°–æ–º–º–µ—Ä—Å', '–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç', '–∫–ª–∏–µ–Ω—Ç', '–ø—Ä–æ–¥—É–∫—Ç', '—Ç–∞—Ä–∏—Ñ',
        'UTM', '—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è', '–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è', '–æ—Ç–∫–∞–∑', '–∫–æ–º–∏—Å—Å–∏—è'
    ]
    found_terms = []
    text_lower = text.lower()
    for term in technical_terms:
        if term.lower() in text_lower:
            found_terms.append(term)
    return found_terms

# === 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¢–û–õ–¨–ö–û –≤ —Ñ–∞–π–ª—ã (–±–µ–∑ –ë–î) ===
def save_to_file_only(filename: str, segments: list, analysis_md: str, audio_hash: str, duration_sec: float) -> str:
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¢–û–õ–¨–ö–û –≤ —Ñ–∞–π–ª—ã (–±–µ–∑ –ë–î).
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ö–µ—à –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä—è–º—É—é ‚Äî –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É Markdown-—Ñ–∞–π–ª—É.
    """
    base_name = Path(filename).stem
    output_path = Path(OUTPUT_DIR)
    output_path.mkdir(exist_ok=True)
    
    # 1. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Markdown-–æ—Ç—á—ë—Ç–∞
    md_path = output_path / f"{base_name}.md"
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(analysis_md)
    print(f"üìÑ Markdown-–æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {md_path}")
    
    # 2. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    json_result = {
        "metadata": {
            "filename": filename,
            "audio_hash": audio_hash,
            "processed_at": datetime.now().isoformat(),
            "duration_sec": duration_sec,
            "segment_count": len(segments),
            "reanalyzed_at": datetime.now().isoformat()  # –º–∞—Ä–∫–µ—Ä –ø–µ—Ä–µ–∞–Ω–∞–ª–∏–∑–∞
        },
        "transcription": [
            {
                "speaker": seg.get('speaker', 'SPEAKER_00'),
                "text": seg.get('text', '').strip(),
                "start": seg.get('start', 0),
                "end": seg.get('end', 0),
                "technical_terms": extract_technical_terms(seg.get('text', ''))
            }
            for seg in segments
        ],
        "analysis": {
            "raw_markdown": analysis_md,
            "extracted_terms": list(set(term for seg in segments for term in extract_technical_terms(seg.get('text', ''))))
        }
    }
    
    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞)
    json_path = output_path / f"{base_name}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_result, f, ensure_ascii=False, indent=2)
    print(f"üì¶ JSON –æ–±–Ω–æ–≤–ª—ë–Ω: {json_path}")
    
    return str(md_path)

# === 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ) ===
def save_to_databases(session, qdrant_client, filename, segments, analysis_md, original_audio_path):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Postgres –∏ Qdrant + –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª—ã –Ω–∞ –¥–∏—Å–∫"""
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—ã...")
    try:
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        with open(original_audio_path, 'rb') as f:
            audio_content = f.read()
        audio_hash = hashlib.sha256(audio_content).hexdigest()
        
        # 1. –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –æ –≤—Å—Ç—Ä–µ—á–µ
        meeting = Meeting(
            filename=filename,
            start_time=datetime.now(),
            duration_sec=sum(seg.get('end', 0) - seg.get('start', 0) for seg in segments),
            audio_hash=audio_hash,
            status='completed',
            quality_score=0.95,
            context_tags=json.dumps(["meeting", "transcription"])
        )
        session.add(meeting)
        session.flush()
        
        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏–∫–µ—Ä–æ–≤
        speaker_cache = {}
        for seg in segments:
            speaker_name = seg.get('speaker', 'SPEAKER_00')
            if speaker_name not in speaker_cache:
                # –ü–æ–∏—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
                speaker = session.query(Speaker).filter_by(external_id=speaker_name).first()
                if not speaker:
                    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
                    speaker = Speaker(
                        external_id=speaker_name,
                        name=speaker_name,
                        role='–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
                    )
                    session.add(speaker)
                    session.flush()
                speaker_cache[speaker_name] = speaker.id
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        for i, seg in enumerate(segments):
            speaker_name = seg.get('speaker', 'SPEAKER_00')
            speaker_id = speaker_cache[speaker_name]
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
            technical_terms = extract_technical_terms(seg.get('text', ''))
            fragment = Fragment(
                meeting_id=meeting.id,
                start_time=seg.get('start', 0),
                end_time=seg.get('end', 0),
                speaker_id=speaker_id,
                text=seg.get('text', '').strip(),
                raw_text=seg.get('text', ''),
                importance_score=0.8,
                business_value='–æ–±—Å—É–∂–¥–µ–Ω–∏–µ',
                technical_terms=json.dumps(technical_terms),
                semantic_cluster=i // 5  # –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ 5 —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            )
            session.add(fragment)
            session.flush()
        
        # 4. –ö–æ–º–º–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π
        session.commit()
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Postgres! –í—Å—Ç—Ä–µ—á–∞ ID: {meeting.id}")
        
        # === –í–°–ï–ì–î–ê —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª—ã –Ω–∞ –¥–∏—Å–∫ (–µ–¥–∏–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å save_to_file_only) ===
        base_name = Path(filename).stem
        output_path = Path(OUTPUT_DIR)
        output_path.mkdir(exist_ok=True)
        
        # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Markdown-–æ—Ç—á—ë—Ç–∞
        md_path = output_path / f"{base_name}.md"
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(analysis_md)
        print(f"üìÑ Markdown-–æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {md_path}")
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON —Å –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π (–≤–∫–ª—é—á–∞—è —Å—Å—ã–ª–∫—É –Ω–∞ –∑–∞–ø–∏—Å—å –≤ –ë–î)
        json_result = {
            "metadata": {
                "filename": filename,
                "audio_hash": audio_hash,
                "processed_at": datetime.now().isoformat(),
                "duration_sec": meeting.duration_sec,
                "segment_count": len(segments),
                "meeting_id": meeting.id  # ‚Üê –∫—Ä–∏—Ç–∏—á–Ω–æ: —Å–≤—è–∑—å —Å –∑–∞–ø–∏—Å—å—é –≤ –ë–î
            },
            "transcription": [
                {
                    "speaker": seg.get('speaker', 'SPEAKER_00'),
                    "text": seg.get('text', '').strip(),
                    "start": seg.get('start', 0),
                    "end": seg.get('end', 0),
                    "technical_terms": extract_technical_terms(seg.get('text', ''))
                }
                for seg in segments
            ],
            "analysis": {
                "raw_markdown": analysis_md,
                "extracted_terms": list(set(term for seg in segments for term in extract_technical_terms(seg.get('text', ''))))
            }
        }
        json_path = output_path / f"{base_name}.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(json_result, f, ensure_ascii=False, indent=2)
        print(f"üì¶ JSON-–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {json_path}")
        
        return str(md_path)
    except Exception as e:
        session.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–∞–∑—ã: {e}")
        traceback.print_exc()
        raise
    finally:
        session.close()

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ===
def main(audio_file: str = None, json_file: str = None, device: str = "cuda", no_db: bool = False):
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (—É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ CLI, –Ω–æ –¥—É–±–ª–∏—Ä—É–µ–º –¥–ª—è –∑–∞—â–∏—Ç—ã)
    if not audio_file and not json_file:
        raise ValueError("–¢—Ä–µ–±—É–µ—Ç—Å—è –∞—É–¥–∏–æ—Ñ–∞–π–ª –ò–õ–ò json_file")
    if audio_file and json_file:
        raise ValueError("–£–∫–∞–∂–∏—Ç–µ –¢–û–õ–¨–ö–û –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    if device == "cuda" and not torch.cuda.is_available():
        print("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ CPU")
        device = "cpu"
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
    is_reanalyze_mode = json_file is not None
    print(f"\nüöÄ –†–µ–∂–∏–º: {'–ü–µ—Ä–µ–∞–Ω–∞–ª–∏–∑ JSON' if is_reanalyze_mode else '–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞'}")
    if is_reanalyze_mode:
        print("‚è≠Ô∏è  –ó–∞–ø–∏—Å—å –≤ –ë–î –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Ä–µ–∂–∏–º–µ --json")
    
    try:
        # === –†–µ–∂–∏–º 1: –ü–µ—Ä–µ–∞–Ω–∞–ª–∏–∑ –∏–∑ JSON ===
        if is_reanalyze_mode:
            if not os.path.exists(json_file):
                print(f"‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_file}")
                sys.exit(1)
            
            segments, orig_filename, audio_hash, duration = load_segments_from_json(json_file)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ {orig_filename}")
            
            # –í —Ä–µ–∂–∏–º–µ –ø–µ—Ä–µ–∞–Ω–∞–ª–∏–∑–∞ –ë–î –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è ‚Äî –Ω–µ—Ç —Å–≤—è–∑–∏ —Å –∏—Å—Ö–æ–¥–Ω—ã–º –∞—É–¥–∏–æ
            session = qdrant_client = None
        
        # === –†–µ–∂–∏–º 2: –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ ===
        else:
            if not os.path.exists(audio_file):
                print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
                sys.exit(1)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î (–µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∞)
            if not no_db:
                print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö...")
                engine = init_db()
                qdrant_client = init_qdrant_client()
                create_collections_if_not_exists(qdrant_client)
                session = get_db_session(engine)
            else:
                print("‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö (—Ä–µ–∂–∏–º --no-db)")
                session = qdrant_client = None
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
            segments = transcribe_and_diarize(audio_file, device=device)
            orig_filename = os.path.basename(audio_file)
            duration = sum(seg.get('end', 0) - seg.get('start', 0) for seg in segments)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞—É–¥–∏–æ)
            with open(audio_file, 'rb') as f:
                audio_hash = hashlib.sha256(f.read()).hexdigest()
        
        # === –û–±—â–∏–π —ç—Ç–∞–ø: –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LLM ===
        print("[DEBUG] –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º —á–µ—Ä–µ–∑ LLM...")
        _free_gpu_memory()
        analysis_md = analyze_with_model(segments)
        
        # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
        if is_reanalyze_mode or no_db:
            # –†–µ–∂–∏–º –±–µ–∑ –ë–î: —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã
            md_path = save_to_file_only(orig_filename, segments, analysis_md, audio_hash, duration)
        else:
            # –ü–æ–ª–Ω—ã–π —Ä–µ–∂–∏–º: –ë–î + —Ñ–∞–π–ª—ã
            md_path = save_to_databases(session, qdrant_client, orig_filename, segments, analysis_md, audio_file)
        
        print(f"\nüéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω! –ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç:\n{md_path}")
        
        # –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –≤ –∫–æ–Ω—Å–æ–ª—å
        summary_start = analysis_md.find("### üìù –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ")
        if summary_start != -1:
            summary_end = analysis_md.find("###", summary_start + 1)
            if summary_end == -1:
                summary_end = len(analysis_md)
            print("\nüìã –ö–†–ê–¢–ö–û–ï –°–û–î–ï–†–ñ–ê–ù–ò–ï:")
            print(analysis_md[summary_start:summary_end].strip())
    
    except KeyboardInterrupt:
        print("\nüõë –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        traceback.print_exc()
        sys.exit(1)