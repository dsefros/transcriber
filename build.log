Using pip 25.2 from /home/dsefros/transcriber/venv/lib/python3.12/site-packages/pip (python 3.12)
Collecting llama-cpp-python==0.3.16
  Downloading llama_cpp_python-0.3.16.tar.gz (50.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.7/50.7 MB 10.9 MB/s  0:00:04
  Installing build dependencies: started
  Running command pip subprocess to install build dependencies
  Using pip 25.2 from /home/dsefros/transcriber/venv/lib/python3.12/site-packages/pip (python 3.12)
  Collecting scikit-build-core>=0.9.2 (from scikit-build-core[pyproject]>=0.9.2)
    Obtaining dependency information for scikit-build-core>=0.9.2 from https://files.pythonhosted.org/packages/43/49/ec16b3db6893db788ae35f98506ff5a9c25dca7eb18cc38ada8a4c1dc944/scikit_build_core-0.11.6-py3-none-any.whl.metadata
    Downloading scikit_build_core-0.11.6-py3-none-any.whl.metadata (18 kB)
  Collecting packaging>=23.2 (from scikit-build-core>=0.9.2->scikit-build-core[pyproject]>=0.9.2)
    Obtaining dependency information for packaging>=23.2 from https://files.pythonhosted.org/packages/b7/b9/c538f279a4e237a006a2c98387d081e9eb060d203d8ed34467cc0f0b9b53/packaging-26.0-py3-none-any.whl.metadata
    Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)
  Collecting pathspec>=0.10.1 (from scikit-build-core>=0.9.2->scikit-build-core[pyproject]>=0.9.2)
    Obtaining dependency information for pathspec>=0.10.1 from https://files.pythonhosted.org/packages/ef/3c/2c197d226f9ea224a9ab8d197933f9da0ae0aac5b6e0f884e2b8d9c8e9f7/pathspec-1.0.4-py3-none-any.whl.metadata
    Downloading pathspec-1.0.4-py3-none-any.whl.metadata (13 kB)
  Downloading scikit_build_core-0.11.6-py3-none-any.whl (185 kB)
  Downloading packaging-26.0-py3-none-any.whl (74 kB)
  Downloading pathspec-1.0.4-py3-none-any.whl (55 kB)
  Installing collected packages: pathspec, packaging, scikit-build-core

  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
  deepfilternet 0.5.6 requires packaging<24.0,>=23.0, but you have packaging 26.0 which is incompatible.
  lightning 2.4.0 requires packaging<25.0,>=20.0, but you have packaging 26.0 which is incompatible.
  Successfully installed packaging-26.0 pathspec-1.0.4 scikit-build-core-0.11.6
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Running command Getting requirements to build wheel
  Getting requirements to build wheel: finished with status 'done'
  Installing backend dependencies: started
  Running command pip subprocess to install backend dependencies
  Using pip 25.2 from /home/dsefros/transcriber/venv/lib/python3.12/site-packages/pip (python 3.12)
  Collecting ninja>=1.5
    Obtaining dependency information for ninja>=1.5 from https://files.pythonhosted.org/packages/ed/de/0e6edf44d6a04dabd0318a519125ed0415ce437ad5a1ec9b9be03d9048cf/ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
    Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
  Installing collected packages: ninja
  Successfully installed ninja-1.13.0
  Installing backend dependencies: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Running command Preparing metadata (pyproject.toml)
  *** scikit-build-core 0.11.6 using CMake 3.28.3 (metadata_wheel)
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting typing-extensions>=4.5.0 (from llama-cpp-python==0.3.16)
  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl.metadata
  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
  Link requires a different Python (3.12.3 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/3a/be/650f9c091ef71cb01d735775d554e068752d3ff63d7943b26316dc401749/numpy-1.21.2.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)
  Link requires a different Python (3.12.3 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/5f/d6/ad58ded26556eaeaa8c971e08b6466f17c4ac4d786cd3d800e26ce59cc01/numpy-1.21.3.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)
  Link requires a different Python (3.12.3 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/fb/48/b0708ebd7718a8933f0d3937513ef8ef2f4f04529f1f66ca86d873043921/numpy-1.21.4.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)
  Link requires a different Python (3.12.3 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/c2/a8/a924a09492bdfee8c2ec3094d0a13f2799800b4fdc9c890738aeeb12c72e/numpy-1.21.5.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)
  Link requires a different Python (3.12.3 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/45/b7/de7b8e67f2232c26af57c205aaad29fe17754f793404f59c8a730c7a191a/numpy-1.21.6.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)
Collecting numpy>=1.20.0 (from llama-cpp-python==0.3.16)
  Obtaining dependency information for numpy>=1.20.0 from https://files.pythonhosted.org/packages/d9/7d/9c8a781c88933725445a859cac5d01b5871588a15969ee6aeb618ba99eee/numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata
  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)
Collecting diskcache>=5.6.1 (from llama-cpp-python==0.3.16)
  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata
  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting jinja2>=2.11.3 (from llama-cpp-python==0.3.16)
  Obtaining dependency information for jinja2>=2.11.3 from https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl.metadata
  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python==0.3.16)
  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/3c/2e/8d0c2ab90a8c1d9a24f0399058ab8519a3279d1bd4289511d74e909f060e/markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata
  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)
Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)
Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)
Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 12.5 MB/s  0:00:01
Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Building wheels for collected packages: llama-cpp-python
  Building wheel for llama-cpp-python (pyproject.toml): started
  Running command Building wheel for llama-cpp-python (pyproject.toml)
  *** scikit-build-core 0.11.6 using CMake 3.28.3 (wheel)
  *** Configuring CMake...
  loading initial cache file /tmp/tmpp1_4onhn/build/CMakeInit.txt
  -- The C compiler identification is GNU 13.3.0
  -- The CXX compiler identification is GNU 13.3.0
  -- Detecting C compiler ABI info
  -- Detecting C compiler ABI info - done
  -- Check for working C compiler: /usr/bin/x86_64-linux-gnu-gcc - skipped
  -- Detecting C compile features
  -- Detecting C compile features - done
  -- Detecting CXX compiler ABI info
  -- Detecting CXX compiler ABI info - done
  -- Check for working CXX compiler: /usr/bin/x86_64-linux-gnu-g++ - skipped
  -- Detecting CXX compile features
  -- Detecting CXX compile features - done
  CMAKE_BUILD_TYPE=Release
  -- Found Git: /usr/bin/git (found version "2.43.0")
  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD
  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
  -- Found Threads: TRUE
  -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF
  -- CMAKE_SYSTEM_PROCESSOR: x86_64
  -- GGML_SYSTEM_ARCH: x86
  -- Including CPU backend
  -- Found OpenMP_C: -fopenmp (found version "4.5")
  -- Found OpenMP_CXX: -fopenmp (found version "4.5")
  -- Found OpenMP: TRUE (found version "4.5")
  -- x86 detected
  -- Adding CPU backend variant ggml-cpu: -march=native
  -- Found CUDAToolkit: /usr/include (found version "12.0.140")
  -- CUDA Toolkit found
  -- Using CUDA architectures: native
  -- The CUDA compiler identification is NVIDIA 12.0.140
  -- Detecting CUDA compiler ABI info
  -- Detecting CUDA compiler ABI info - done
  -- Check for working CUDA compiler: /usr/bin/nvcc - skipped
  -- Detecting CUDA compile features
  -- Detecting CUDA compile features - done
  -- CUDA host compiler is GNU 12.4.0
  -- Including CUDA backend
  -- ggml version: 0.0.1
  -- ggml commit:  4227c9b
  CMake Warning (dev) at CMakeLists.txt:13 (install):
    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.
  Call Stack (most recent call first):
    CMakeLists.txt:108 (llama_cpp_python_install_target)
  This warning is for project developers.  Use -Wno-dev to suppress it.

  CMake Warning (dev) at CMakeLists.txt:21 (install):
    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.
  Call Stack (most recent call first):
    CMakeLists.txt:108 (llama_cpp_python_install_target)
  This warning is for project developers.  Use -Wno-dev to suppress it.

  CMake Warning (dev) at CMakeLists.txt:13 (install):
    Target ggml has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.
  Call Stack (most recent call first):
    CMakeLists.txt:109 (llama_cpp_python_install_target)
  This warning is for project developers.  Use -Wno-dev to suppress it.

  CMake Warning (dev) at CMakeLists.txt:21 (install):
    Target ggml has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.
  Call Stack (most recent call first):
    CMakeLists.txt:109 (llama_cpp_python_install_target)
  This warning is for project developers.  Use -Wno-dev to suppress it.

  CMake Warning (dev) at CMakeLists.txt:13 (install):
    Target mtmd has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.
  Call Stack (most recent call first):
    CMakeLists.txt:162 (llama_cpp_python_install_target)
  This warning is for project developers.  Use -Wno-dev to suppress it.

  CMake Warning (dev) at CMakeLists.txt:21 (install):
    Target mtmd has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.
  Call Stack (most recent call first):
    CMakeLists.txt:162 (llama_cpp_python_install_target)
  This warning is for project developers.  Use -Wno-dev to suppress it.

  -- Configuring done (18.6s)
  -- Generating done (0.0s)
  -- Build files have been written to: /tmp/tmpp1_4onhn/build
  *** Building project with Ninja...
  Change Dir: '/tmp/tmpp1_4onhn/build'

  Run Build Command(s): ninja -v
  [1/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/hbm.cpp
  [2/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-threading.cpp
  [3/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml.cpp
  [4/183] /usr/bin/x86_64-linux-gnu-gcc -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-alloc.c
  [5/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/traits.cpp
  [6/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp
  [7/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp
  [8/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp
  [9/183] /usr/bin/x86_64-linux-gnu-gcc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/arch/x86/quants.c
  [10/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/vec.cpp
  [11/183] /usr/bin/x86_64-linux-gnu-gcc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c
  [12/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-opt.cpp
  [13/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-backend.cpp
  [14/183] /usr/bin/x86_64-linux-gnu-gcc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/quants.c
  [15/183] /usr/bin/x86_64-linux-gnu-gcc -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml.c
  [16/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp
  [17/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/arch/x86/repack.cpp
  [18/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp
  [19/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/repack.cpp
  [20/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/add-id.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/add-id.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/add-id.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/add-id.cu.o
  [21/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp
  [22/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/argsort.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o
  [23/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/acc.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o
  [24/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/arange.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o
  [25/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/argmax.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o
  [26/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/clamp.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o
  [27/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/gguf.cpp
  [28/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/conv2d-transpose.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o
  [29/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/concat.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o
  [30/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/conv-transpose-1d.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o
  [31/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/cross-entropy-loss.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o
  [32/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/conv2d-dw.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o
  [33/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/diagmask.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o
  [34/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/count-equal.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o
  [35/183] /usr/bin/x86_64-linux-gnu-gcc -DGGML_BUILD -DGGML_COMMIT=\"4227c9b\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.0.1\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-quants.c
  [36/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/convert.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o
  [37/183] : && /usr/bin/x86_64-linux-gnu-g++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libggml-base.so -o bin/libggml-base.so vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o  -Wl,-rpath,"\$ORIGIN"  -lm && :
  [38/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/cpy.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o
  [39/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f32.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o
  [40/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/binbcast.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o
  [41/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/fattn.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o
  [42/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o
  [43/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cpu/ops.cpp
  [44/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/gla.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o
  [45/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/im2col.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o
  [46/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/mmq.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o
  [47/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/norm.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o
  [48/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/out-prod.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o
  [49/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/pad.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o
  [50/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/getrows.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o
  [51/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/opt-step-adamw.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o
  [52/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-sgd.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-sgd.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/opt-step-sgd.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-sgd.cu.o
  [53/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/quantize.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o
  [54/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/pool2d.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o
  [55/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/roll.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/roll.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/roll.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/roll.cu.o
  [56/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/scale.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o
  [57/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softcap.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softcap.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/softcap.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softcap.cu.o
  [58/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/ssm-conv.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o
  [59/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/sumrows.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o
  [60/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/ggml-cuda.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o
  [61/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mean.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mean.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/mean.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mean.cu.o
  [62/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/tsembd.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o
  [63/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/set-rows.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/set-rows.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/set-rows.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/set-rows.cu.o
  [64/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/upscale.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o
  [65/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/fattn-wmma-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o
  [66/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/rope.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o
  [67/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/unary.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o
  [68/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/softmax.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o
  [69/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/wkv.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o
  [70/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/sum.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o
  [71/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/ssm-scan.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o
  [72/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o
  [73/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o
  [74/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o
  [75/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o
  [76/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o
  [77/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o
  [78/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o
  [79/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvf.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvf.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/mmvf.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvf.cu.o
  [80/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o
  [81/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/mmvq.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o
  [82/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o
  [83/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o
  [84/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o
  [85/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o
  [86/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o
  [87/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o
  [88/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o
  [89/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o
  [90/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o
  [91/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o
  [92/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o
  [93/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o
  [94/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o
  [95/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o
  [96/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o
  [97/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o
  [98/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o
  [99/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmf.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmf.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/mmf.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmf.cu.o
  [100/183] : && /usr/bin/x86_64-linux-gnu-g++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libggml-cpu.so -o bin/libggml-cpu.so vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o vendor/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o  -Wl,-rpath,"\$ORIGIN"  bin/libggml-base.so  /usr/lib/gcc/x86_64-linux-gnu/13/libgomp.so  /usr/lib/x86_64-linux-gnu/libpthread.a && :
  [101/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o
  [102/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama.cpp
  [103/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o -MF vendor/llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o.d -o vendor/llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-backend-reg.cpp
  [104/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o
  [105/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-adapter.cpp
  [106/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-cparams.cpp
  [107/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o
  [108/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-arch.cpp
  [109/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-hparams.cpp
  [110/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o
  [111/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-io.cpp
  [112/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o
  [113/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-impl.cpp
  [114/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-memory.cpp
  [115/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-batch.cpp
  [116/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o
  [117/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-chat.cpp
  [118/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o
  [119/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-graph.cpp
  [120/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-mmap.cpp
  [121/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-kv-cache-unified-iswa.cpp
  [122/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-model-saver.cpp
  [123/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-memory-hybrid.cpp
  [124/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-context.cpp
  [125/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-memory-recurrent.cpp
  [126/183] /usr/bin/x86_64-linux-gnu-g++   -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -c /tmp/tmpp1_4onhn/build/vendor/llama.cpp/common/build-info.cpp
  [127/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o
  [128/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/unicode-data.cpp
  [129/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o
  [130/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-kv-cache-unified.cpp
  [131/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-model-loader.cpp
  [132/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/console.cpp
  [133/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-grammar.cpp
  [134/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o
  [135/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/llguidance.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/llguidance.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/llguidance.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/llguidance.cpp
  [136/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/log.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/log.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/log.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/log.cpp
  [137/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/chat-parser.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/chat-parser.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/chat-parser.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/chat-parser.cpp
  [138/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/ngram-cache.cpp
  [139/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-vocab.cpp
  [140/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-quant.cpp
  [141/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/sampling.cpp
  [142/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/speculative.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/speculative.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/speculative.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/speculative.cpp
  [143/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-sampling.cpp
  [144/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/json-partial.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/json-partial.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/json-partial.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/json-partial.cpp
  [145/183] /usr/bin/x86_64-linux-gnu-g++   -O3 -DNDEBUG -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/deprecation-warning.cpp
  [146/183] /usr/bin/x86_64-linux-gnu-g++   -O3 -DNDEBUG -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/deprecation-warning.cpp
  [147/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/mtmd-audio.cpp
  [148/183] /usr/bin/x86_64-linux-gnu-g++   -O3 -DNDEBUG -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/deprecation-warning.cpp
  [149/183] /usr/bin/x86_64-linux-gnu-g++   -O3 -DNDEBUG -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/deprecation-warning.cpp
  [150/183] : && /usr/bin/x86_64-linux-gnu-g++ -O3 -DNDEBUG  vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o -o vendor/llama.cpp/tools/mtmd/llama-llava-cli   && :
  [151/183] : && /usr/bin/x86_64-linux-gnu-g++ -O3 -DNDEBUG  vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o -o vendor/llama.cpp/tools/mtmd/llama-gemma3-cli   && :
  [152/183] : && /usr/bin/x86_64-linux-gnu-g++ -O3 -DNDEBUG  vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o -o vendor/llama.cpp/tools/mtmd/llama-minicpmv-cli   && :
  [153/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/common.cpp
  [154/183] : && /usr/bin/x86_64-linux-gnu-g++ -O3 -DNDEBUG  vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o -o vendor/llama.cpp/tools/mtmd/llama-qwen2vl-cli   && :
  [155/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/mtmd.cpp
  [156/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/unicode.cpp
  [157/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/include -O3 -DNDEBUG -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/mtmd-cli.cpp
  [158/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/regex-partial.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/regex-partial.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/regex-partial.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/regex-partial.cpp
  [159/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o
  [160/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o
  [161/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/clip.cpp
  [162/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/json-schema-to-grammar.cpp
  [163/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o
  [164/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o
  [165/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o
  [166/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o
  [167/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/arg.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/arg.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/arg.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/arg.cpp
  [168/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o
  [169/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-mxfp4.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-mxfp4.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-mxfp4.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-mxfp4.cu.o
  [170/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o
  [171/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o -MF vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o.d -o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/llama-model.cpp
  [172/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o
  [173/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o
  [174/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/../../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o -MF vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o.d -o vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/tools/mtmd/mtmd-helper.cpp
  [175/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o
  [176/183] /usr/bin/x86_64-linux-gnu-g++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/../vendor -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/src/../include -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/chat.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/chat.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/chat.cpp.o -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/common/chat.cpp
  [177/183] /usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/.. -I/tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o -MF vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o.d -x cu -c /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/vendor/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu -o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o
  [178/183] : && /usr/lib/nvidia-cuda-toolkit/bin/g++ -fPIC  -shared -Wl,-soname,libggml-cuda.so -o bin/libggml-cuda.so vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/add-id.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mean.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmf.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvf.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-sgd.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/roll.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/set-rows.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softcap.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-mxfp4.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o vendor/llama.cpp/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o  -Wl,-rpath,"\$ORIGIN"  bin/libggml-base.so  /usr/lib/x86_64-linux-gnu/libcudart.so  /usr/lib/x86_64-linux-gnu/libcublas.so  /usr/lib/x86_64-linux-gnu/libcuda.so  /usr/lib/x86_64-linux-gnu/libcublasLt.so  /usr/lib/x86_64-linux-gnu/libculibos.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl -L"/usr/lib/x86_64-linux-gnu/stubs" -L"/usr/lib/x86_64-linux-gnu" && :
  [179/183] : && /usr/bin/x86_64-linux-gnu-g++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libggml.so -o bin/libggml.so vendor/llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o  -Wl,-rpath,"\$ORIGIN"  -ldl  bin/libggml-cpu.so  bin/libggml-cuda.so  bin/libggml-base.so && :
  [180/183] : && /usr/bin/x86_64-linux-gnu-g++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllama.so -o bin/libllama.so vendor/llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o vendor/llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o  -Wl,-rpath,"\$ORIGIN"  bin/libggml.so  bin/libggml-cpu.so  bin/libggml-cuda.so  bin/libggml-base.so && :
  [181/183] : && /usr/bin/x86_64-linux-gnu-g++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libmtmd.so -o vendor/llama.cpp/tools/mtmd/libmtmd.so vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o vendor/llama.cpp/tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o  -Wl,-rpath,"\$ORIGIN"  bin/libllama.so  bin/libggml.so  bin/libggml-cpu.so  bin/libggml-cuda.so  bin/libggml-base.so && :
  [182/183] : && /usr/bin/cmake -E rm -f vendor/llama.cpp/common/libcommon.a && /usr/bin/x86_64-linux-gnu-ar qc vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/arg.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/chat-parser.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/chat.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/json-partial.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/llguidance.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/log.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/regex-partial.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/speculative.cpp.o && /usr/bin/x86_64-linux-gnu-ranlib vendor/llama.cpp/common/libcommon.a && :
  [183/183] : && /usr/bin/x86_64-linux-gnu-g++ -O3 -DNDEBUG  vendor/llama.cpp/tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o -o vendor/llama.cpp/tools/mtmd/llama-mtmd-cli  -Wl,-rpath,/tmp/tmpp1_4onhn/build/vendor/llama.cpp/tools/mtmd:/tmp/tmpp1_4onhn/build/bin:  vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/tools/mtmd/libmtmd.so  bin/libllama.so  bin/libggml.so  bin/libggml-cpu.so  bin/libggml-cuda.so  bin/libggml-base.so && :

  *** Installing project into wheel...
  -- Install configuration: "Release"
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/libggml-cpu.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/libggml-cuda.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/libggml.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-cpu.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-alloc.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-backend.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-blas.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-cann.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-cpp.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-cuda.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-opt.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-metal.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-rpc.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-sycl.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-vulkan.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/ggml-webgpu.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/gguf.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/libggml-base.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/cmake/ggml/ggml-config.cmake
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/cmake/ggml/ggml-version.cmake
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/libllama.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/llama.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/llama-cpp.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/cmake/llama/llama-config.cmake
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/cmake/llama/llama-version.cmake
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/bin/convert_hf_to_gguf.py
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/pkgconfig/llama.pc
  -- Installing: /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/llama_cpp/lib/libllama.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/llama_cpp/lib/libllama.so
  -- Installing: /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/llama_cpp/lib/libggml.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/llama_cpp/lib/libggml.so
  -- Installing: /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/llama_cpp/lib/libggml-base.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/llama_cpp/lib/libggml-base.so
  -- Installing: /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/llama_cpp/lib/libggml-cpu.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/llama_cpp/lib/libggml-cpu.so
  -- Installing: /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/llama_cpp/lib/libggml-cuda.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/llama_cpp/lib/libggml-cuda.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/lib/libmtmd.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/mtmd.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/include/mtmd-helper.h
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/bin/llama-mtmd-cli
  -- Set non-toolchain portion of runtime path of "/tmp/tmpp1_4onhn/wheel/platlib/bin/llama-mtmd-cli" to ""
  -- Installing: /tmp/pip-install-pzie7nae/llama-cpp-python_696939af292245e18a618b4ff15d0615/llama_cpp/lib/libmtmd.so
  -- Installing: /tmp/tmpp1_4onhn/wheel/platlib/llama_cpp/lib/libmtmd.so
  *** Making wheel...
  *** Created llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl
  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'
  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl size=49204948 sha256=75bda34caa07623f5eed0310c8e4a54f38c01828fd66df88d4a9f5a9aa83f013
  Stored in directory: /tmp/pip-ephem-wheel-cache-sff3lcf5/wheels/90/82/ab/8784ee3fb99ddb07fd36a679ddbe63122cc07718f6c1eb3be8
Successfully built llama-cpp-python
Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python
  Attempting uninstall: typing-extensions
    Found existing installation: typing_extensions 4.15.0
    Uninstalling typing_extensions-4.15.0:
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/__pycache__/typing_extensions.cpython-312.pyc
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/typing_extensions-4.15.0.dist-info/
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/typing_extensions.py
      Successfully uninstalled typing_extensions-4.15.0
  Attempting uninstall: numpy
    Found existing installation: numpy 1.26.4
    Uninstalling numpy-1.26.4:
      Removing file or directory /home/dsefros/transcriber/venv/bin/f2py
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/numpy-1.26.4.dist-info/
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/numpy.libs/
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/numpy/
      Successfully uninstalled numpy-1.26.4
  changing mode of /home/dsefros/transcriber/venv/bin/f2py to 755
  changing mode of /home/dsefros/transcriber/venv/bin/numpy-config to 755
  Attempting uninstall: MarkupSafe
    Found existing installation: MarkupSafe 3.0.2
    Uninstalling MarkupSafe-3.0.2:
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/MarkupSafe-3.0.2.dist-info/
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/markupsafe/
      Successfully uninstalled MarkupSafe-3.0.2
  Attempting uninstall: jinja2
    Found existing installation: Jinja2 3.1.6
    Uninstalling Jinja2-3.1.6:
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/jinja2-3.1.6.dist-info/
      Removing file or directory /home/dsefros/transcriber/venv/lib/python3.12/site-packages/jinja2/
      Successfully uninstalled Jinja2-3.1.6

ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
deepfilternet 0.5.6 requires numpy<2.0,>=1.22, but you have numpy 2.4.1 which is incompatible.
numba 0.61.2 requires numpy<2.3,>=1.24, but you have numpy 2.4.1 which is incompatible.
Successfully installed MarkupSafe-3.0.3 diskcache-5.6.3 jinja2-3.1.6 llama-cpp-python-0.3.16 numpy-2.4.1 typing-extensions-4.15.0

[notice] A new release of pip is available: 25.2 -> 25.3
[notice] To update, run: pip install --upgrade pip
